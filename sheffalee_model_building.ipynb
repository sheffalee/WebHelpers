{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MODEL BUILDING\n",
        "\n",
        "The models i built are:\n",
        "1.Roberta\n",
        "2.Vader\n",
        "\n",
        "1.Roberta:\n",
        "Roberta, developed by Facebook AI, enhances BERT through robust pretraining and more data.It achieves state-of-the-art results on various NLP tasks due to its deeper language understanding.\n",
        "The model has proven effective in a wide range of applications, from language translation to question answering.Roberta's training process involves removing the next sentence prediction task and using larger batch sizes.These improvements contribute to its superior performance over BERT in many natural language processing benchmarks.\n",
        "\n",
        "Advantages of Roberta:\n",
        "Improved NLP model by Facebook AI, outperforms BERT with robust pretraining and larger data.Broader language understanding, better handling of informal language, and domain-specific jargon.Generalizes well across tasks, advancing NLP research and enabling practical applications.\n",
        "\n",
        "2.Vader:\n",
        "VADER, or Valence Aware Dictionary and sEntiment Reasoner, is a lexicon-based sentiment analysis tool.It excels in analyzing social media content, considering nuances and informal language.\n",
        "VADER employs a human-annotated lexicon to determine sentiment scores for words, capturing intensity and negations.Its design enables accurate sentiment analysis for short texts, such as tweets and posts.VADER's effectiveness and simplicity make it a popular choice for social media monitoring and opinion mining.\n",
        "\n",
        "Advantages of Vader:\n",
        "Lexicon-based sentiment analysis tool for social media text, capturing nuances effectively.Considers word polarity, intensity, negations, and punctuation for accurate sentiment analysis.Fast, simple, and versatile, influencing sentiment analysis research and industry applications.\n",
        "\n",
        "I built few models and analysed among these Roberta and Vader where the best performing models.So i would suggest vader and roberta as the best models that can be used in the implementation of the WebHelpers project.\n",
        "\n",
        "Link for the dataset :https://drive.google.com/file/d/1CZpQwEXjFiqq4YBwz8QDYsuV18b5moaZ/view?usp=sharing\n",
        "\n",
        "The dataset is very large so i have taken only few rows for the model building and training.\n",
        "\n",
        "To avoid errors , make sure you install all the packages used in this code in your environment."
      ],
      "metadata": {
        "id": "-bC3pV1mvcZg"
      },
      "id": "-bC3pV1mvcZg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cc1652",
      "metadata": {
        "id": "93cc1652"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296cec92",
      "metadata": {
        "id": "296cec92"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Reviews.csv')\n",
        "print(df.shape)\n",
        "#I have used a very large dataset consisting of 5lakhs of records.\n",
        "# In order to decrease the runtime you can modify the number of records\n",
        "# you needed depending on the GPU availability.\n",
        "df = df.head(500)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa333db",
      "metadata": {
        "id": "cfa333db"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449af4a4",
      "metadata": {
        "id": "449af4a4"
      },
      "outputs": [],
      "source": [
        "ax = df['Score'].value_counts().sort_index() \\\n",
        "    .plot(kind='bar',\n",
        "          title='Count of Reviews by Stars',\n",
        "          figsize=(10, 5))\n",
        "ax.set_xlabel('Review Stars')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6ce3b1",
      "metadata": {
        "id": "ed6ce3b1"
      },
      "outputs": [],
      "source": [
        "example = df['Text'][50]\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e60507",
      "metadata": {
        "id": "49e60507"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokens = nltk.word_tokenize(example)\n",
        "tokens[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c673e5",
      "metadata": {
        "id": "03c673e5"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48df4f23",
      "metadata": {
        "id": "48df4f23"
      },
      "outputs": [],
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98aee959",
      "metadata": {
        "id": "98aee959"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c40cd44",
      "metadata": {
        "id": "4c40cd44"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('I am so happy!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae5a7ab",
      "metadata": {
        "id": "fae5a7ab"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('This is the worst thing ever.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f712d9d6",
      "metadata": {
        "id": "f712d9d6"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores(example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4be6b18",
      "metadata": {
        "id": "a4be6b18"
      },
      "outputs": [],
      "source": [
        "# Run the polarity score on the entire dataset\n",
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = row['Text']\n",
        "    myid = row['Id']\n",
        "    res[myid] = sia.polarity_scores(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b169575a",
      "metadata": {
        "id": "b169575a"
      },
      "outputs": [],
      "source": [
        "vaders = pd.DataFrame(res).T\n",
        "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
        "vaders = vaders.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75eafe8c",
      "metadata": {
        "id": "75eafe8c"
      },
      "outputs": [],
      "source": [
        "# Now we have sentiment score and metadata\n",
        "vaders.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73cea4da",
      "metadata": {
        "id": "73cea4da"
      },
      "outputs": [],
      "source": [
        "ax = sns.barplot(data=vaders, x='Score', y='compound')\n",
        "ax.set_title('Compund Score by Amazon Star Review')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31a7d04",
      "metadata": {
        "id": "c31a7d04"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
        "sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])\n",
        "sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])\n",
        "sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])\n",
        "axs[0].set_title('Positive')\n",
        "axs[1].set_title('Neutral')\n",
        "axs[2].set_title('Negative')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2444228",
      "metadata": {
        "id": "b2444228"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa1eef3",
      "metadata": {
        "id": "faa1eef3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "example = df['Text'][50]\n",
        "print(example)\n",
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "input_ids = encoded_text['input_ids']\n",
        "attention_mask = encoded_text['attention_mask']\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    logits = output.logits\n",
        "\n",
        "scores = torch.softmax(logits, dim=1)\n",
        "scores_dict = {\n",
        "    'roberta_neg': scores[0, 0].item(),\n",
        "    'roberta_neu': scores[0, 1].item(),\n",
        "    'roberta_pos': scores[0, 2].item()\n",
        "}\n",
        "print(scores_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce4ea22",
      "metadata": {
        "id": "3ce4ea22"
      },
      "outputs": [],
      "source": [
        "# VADER results on example\n",
        "print(example)\n",
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ddeaf9f",
      "metadata": {
        "id": "2ddeaf9f"
      },
      "outputs": [],
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203a916d",
      "metadata": {
        "id": "203a916d"
      },
      "outputs": [],
      "source": [
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        text = row['Text']\n",
        "        myid = row['Id']\n",
        "        vader_result = sia.polarity_scores(text)\n",
        "        vader_result_rename = {}\n",
        "        for key, value in vader_result.items():\n",
        "            vader_result_rename[f\"vader_{key}\"] = value\n",
        "        roberta_result = polarity_scores_roberta(text)\n",
        "        both = {**vader_result_rename, **roberta_result}\n",
        "        res[myid] = both\n",
        "    except RuntimeError:\n",
        "        print(f'Broke for id {myid}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39b2475",
      "metadata": {
        "id": "a39b2475"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(res).T\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
        "results_df = results_df.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176343a4",
      "metadata": {
        "id": "176343a4"
      },
      "outputs": [],
      "source": [
        "#Compare scores between models\n",
        "\n",
        "results_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f094f86",
      "metadata": {
        "id": "9f094f86"
      },
      "outputs": [],
      "source": [
        "#Combine and compare\n",
        "sns.pairplot(data=results_df,\n",
        "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
        "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
        "            hue='Score',\n",
        "            palette='tab10')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c3653f7",
      "metadata": {
        "id": "7c3653f7"
      },
      "outputs": [],
      "source": [
        "#Review examples\n",
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('roberta_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18db932a",
      "metadata": {
        "id": "18db932a"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('vader_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d847eed",
      "metadata": {
        "id": "6d847eed"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8622af",
      "metadata": {
        "id": "ab8622af"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02382de4",
      "metadata": {
        "id": "02382de4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba5e0b5",
      "metadata": {
        "id": "7ba5e0b5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}